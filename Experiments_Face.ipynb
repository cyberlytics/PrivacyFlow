{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experimente - Datensatz Gesichter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings und Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#autoreload other packages when code changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T19:52:17.810548Z",
     "end_time": "2023-08-03T19:52:17.882547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(20)  #Reproduzierbarkeit\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import copy\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.accountants import RDPAccountant\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T19:52:17.855547Z",
     "end_time": "2023-08-03T19:52:21.080946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Own Code\n",
    "from privacyflow.configs import path_configs\n",
    "from privacyflow.datasets import faces_dataset\n",
    "from privacyflow.models import face_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T19:52:21.081948Z",
     "end_time": "2023-08-03T19:52:21.184949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T19:52:21.175950Z",
     "end_time": "2023-08-03T19:52:21.301949Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "label_columns = 'all'  #40 attributes\n",
    "\n",
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "\n",
    "    # torchvision.transforms.Resize((224,224)), # Resize is done by model\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test = torchvision.transforms.Compose([\n",
    "    # torchvision.transforms.Resize((224,224)), # Resize is done by model\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\", transform=data_augmentation_train)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "val_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\", transform=data_augmentation_test)\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "test_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\", transform=data_augmentation_test)\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T20:59:45.034507Z",
     "end_time": "2023-08-03T20:59:53.618327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 218, 178])\n"
     ]
    }
   ],
   "source": [
    "for (input, label) in train_dataloader:\n",
    "    print(input.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T21:00:11.441467Z",
     "end_time": "2023-08-03T21:00:34.522853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model - Base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_base_all_attributes = face_models.get_FaceModelBase(40).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_base_all_attributes.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T16:31:39.717459Z",
     "end_time": "2023-08-03T16:31:40.183457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bd18e81a048496ea13f7c4e8d602d7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Train Loss: 0.41122 Val Loss: 0.33358 Val Accuracy (all attributes): 0.8578346000906025\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2a6636f67bb48e7a9f54ded8858a162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Train Loss: 0.27866 Val Loss: 0.23901 Val Accuracy (all attributes): 0.8961959530880355\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fa2738e081c405b8a1fe9a37fc6178b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Train Loss: 0.23990 Val Loss: 0.24795 Val Accuracy (all attributes): 0.8901696280263754\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de55404339df4396965715d23d2d24a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Train Loss: 0.22580 Val Loss: 0.21224 Val Accuracy (all attributes): 0.9069185080787235\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d2801899bac4bd7a03f28d943d80bb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Train Loss: 0.21757 Val Loss: 0.22101 Val Accuracy (all attributes): 0.903400110736397\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45dfc9cdf3ae4461b9679b33a407bbda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Train Loss: 0.21171 Val Loss: 0.21374 Val Accuracy (all attributes): 0.9071236220868777\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d73b869a22264fe5bec6d60f9fab98a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Train Loss: 0.20751 Val Loss: 0.20381 Val Accuracy (all attributes): 0.9107124880455026\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2105930ce7645a59b23c016b44695fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Train Loss: 0.20394 Val Loss: 0.21619 Val Accuracy (all attributes): 0.9067712790053858\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(8):\n",
    "    model_base_all_attributes.train()\n",
    "    epoch_loss = 0.0\n",
    "    for model_inputs, labels in tqdm(train_dataloader):\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_outputs = model_base_all_attributes(model_inputs)\n",
    "        loss = criterion(model_outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    val_loss = 0.0\n",
    "    num_corrects = 0\n",
    "    model_base_all_attributes.eval()\n",
    "    for model_inputs, labels in val_dataloader:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model_outputs = model_base_all_attributes(model_inputs)\n",
    "        loss = criterion(model_outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        num_corrects += int((model_outputs.round() == labels).sum())\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1:2}\",\n",
    "          f\"Train Loss: {epoch_loss / len(train_dataloader):.5f}\",\n",
    "          f\"Val Loss: {val_loss / len(val_dataloader):.5f}\",\n",
    "          f\"Val Accuracy (all attributes): {num_corrects / (len(val_dataset) * 40)}\"\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T16:31:40.186456Z",
     "end_time": "2023-08-03T17:33:30.135401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (all attributes): 0.9030044584710951\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "num_corrects = 0\n",
    "for model_inputs, labels in test_dataloader:\n",
    "    model_inputs = model_inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    model_outputs = model_base_all_attributes(model_inputs)\n",
    "    num_corrects += int((model_outputs.round() == labels).sum())\n",
    "print(f\"Test Accuracy (all attributes): {num_corrects / (len(test_dataset) * 40)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T17:33:30.143400Z",
     "end_time": "2023-08-03T17:34:31.549014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "torch.save(model_base_all_attributes.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T18:05:55.293652Z",
     "end_time": "2023-08-03T18:05:55.483186Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Membership Inference Attacke"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Create Dataset and Dataloader for Shadow Modell\n",
    "shadow_model_ds1 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"all\", transform=data_augmentation_train)\n",
    "shadow_model_dl1 = DataLoader(dataset=shadow_model_ds1, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds2 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\", transform=data_augmentation_train)\n",
    "shadow_model_dl2 = DataLoader(dataset=shadow_model_ds2, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds3 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(1, 100_000))\n",
    "shadow_model_dl3 = DataLoader(dataset=shadow_model_ds3, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds4 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(100_000, 202_600))\n",
    "shadow_model_dl4 = DataLoader(dataset=shadow_model_ds4, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds5 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(50_000, 150_000))\n",
    "shadow_model_dl5 = DataLoader(dataset=shadow_model_ds5, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds6 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train,\n",
    "                                              custom_range=list(range(50_000, 100_000)) + list(range(150_000, 202_600)))\n",
    "shadow_model_dl6 = DataLoader(dataset=shadow_model_ds6, batch_size=128, shuffle=True, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T00:10:04.762342Z",
     "end_time": "2023-08-03T00:10:21.398707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training of shadow model 1\n",
      "Start training of shadow model 2\n",
      "Start training of shadow model 3\n",
      "Start training of shadow model 4\n",
      "Start training of shadow model 5\n",
      "Start training of shadow model 6\n"
     ]
    }
   ],
   "source": [
    "#Train Shadow Models\n",
    "shadow_models = []\n",
    "for i, datal in enumerate([shadow_model_dl1, shadow_model_dl2, shadow_model_dl3,\n",
    "                           shadow_model_dl4, shadow_model_dl5, shadow_model_dl6]):\n",
    "    print(f\"Start training of shadow model {i + 1}\")\n",
    "    shadow_model = face_models.get_FaceModelBase(40).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(shadow_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(8):\n",
    "        #print(f\"Epoch {epoch+1} for shadow model {i+1}\")\n",
    "        for model_inputs, labels in datal:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model_outputs = shadow_model(model_inputs)\n",
    "            loss = criterion(model_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    shadow_models.append(shadow_model)\n",
    "    #print(f\"Finished training of shadow model {i+1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T00:10:21.398707Z",
     "end_time": "2023-08-03T04:22:40.667556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Create Dataset for meta classifier\n",
    "#Datasets with included datapoints\n",
    "included_ranges = [\n",
    "    range(1, 202_600),  #used in shadow_model_1\n",
    "    range(1, 162_771),  #used in shadow_model_2\n",
    "    range(1, 100_000),  #used in shadow_model_3\n",
    "    range(100_000, 202_600),  #used in shadow_model_4\n",
    "    range(50_000, 150_000),  #used in shadow_model_5\n",
    "    list(range(50_000, 100_000)) + list(range(100_000, 150_000)),  #used in shadow_model_6\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T04:22:40.667556Z",
     "end_time": "2023-08-03T04:22:40.798853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start getting data from shadow model 1\n",
      "Start getting data from shadow model 2\n",
      "Start getting data from shadow model 3\n",
      "Start getting data from shadow model 4\n",
      "Start getting data from shadow model 5\n",
      "Start getting data from shadow model 6\n"
     ]
    }
   ],
   "source": [
    "#Create Dataset for meta classifier\n",
    "#get distributions from shadow models\n",
    "\n",
    "dfs_total = []\n",
    "ds = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"all\", transform=data_augmentation_test)\n",
    "dl = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "for index, (shadow_model, included_range) in enumerate(zip(shadow_models, included_ranges)):\n",
    "    print(f\"Start getting data from shadow model {index + 1}\")\n",
    "    shadow_model = shadow_model.to(device)\n",
    "    shadow_model.eval()\n",
    "    dfs_batches = []\n",
    "    for model_inputs, labels in dl:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        preds = shadow_model(model_inputs)\n",
    "        preds_df = pd.DataFrame(preds.cpu().detach().numpy())\n",
    "        dfs_batches.append(preds_df)\n",
    "    df_epoch = pd.concat(dfs_batches)\n",
    "    df_epoch['target'] = [int(index in included_range) for index in range(1, 202_600)]\n",
    "    dfs_total.append(df_epoch)\n",
    "\n",
    "dfs_total = pd.concat(dfs_total).reset_index()\n",
    "dfs_total.to_csv(path_configs.FACE_MI_DATA, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T04:22:40.798853Z",
     "end_time": "2023-08-03T05:11:35.469631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f24546bd403541bf8fb9f2a84edc1a55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 498897.81840, Acc: 0.47468\n",
      "Predicted Label One 547056.0 times and Label Zero 668538.0 times\n",
      "Train Epoch 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abfc8c68c3414355b32553cc5ce2e6d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 499025.02948, Acc: 0.47454\n",
      "Predicted Label One 547490.0 times and Label Zero 668104.0 times\n",
      "Train Epoch 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d6dc2befe0a4b8fa87858b449214b97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 498827.50590, Acc: 0.47475\n",
      "Predicted Label One 547276.0 times and Label Zero 668318.0 times\n",
      "Train Epoch 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9358c8a20b624e59921f87f5d02e3429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 499425.00000, Acc: 0.47412\n",
      "Predicted Label One 547501.0 times and Label Zero 668093.0 times\n",
      "Train Epoch 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df58e8f207314fb484670df83e48822f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 499026.26769, Acc: 0.47454\n",
      "Predicted Label One 546952.0 times and Label Zero 668642.0 times\n",
      "Train Epoch 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fd1f7dd8c7b405ea9b4cb2741e1938e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 499131.41215, Acc: 0.47443\n",
      "Predicted Label One 547315.0 times and Label Zero 668279.0 times\n",
      "Train Epoch 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c603398056314bfbb7ce2b19eccbc3c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 499317.80661, Acc: 0.47424\n",
      "Predicted Label One 547510.0 times and Label Zero 668084.0 times\n",
      "Train Epoch 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aa05b136b1843ee906b380985cd7326"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 499418.18986, Acc: 0.47413\n",
      "Predicted Label One 547176.0 times and Label Zero 668418.0 times\n",
      "Train Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d030e6ff164c4c2099d47a2fcc5bda05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 499051.13503, Acc: 0.47452\n",
      "Predicted Label One 547509.0 times and Label Zero 668085.0 times\n",
      "Train Epoch 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697395811e154611b29f195df932118a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 499227.15212, Acc: 0.47433\n",
      "Predicted Label One 547429.0 times and Label Zero 668165.0 times\n",
      "Train Epoch 11\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9497 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d1f8c4f629f4b4fb27a3ff11a071a7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m time_ones \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs,label \u001B[38;5;129;01min\u001B[39;00m tqdm(meta_classifier_dl):\n\u001B[0;32m     20\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     21\u001B[0m     label \u001B[38;5;241m=\u001B[39m label\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Train meta classifier\n",
    "dfs_total = pd.read_csv(path_configs.FACE_MI_DATA)\n",
    "if \"index\" in dfs_total:\n",
    "    dfs_total = dfs_total.drop(columns='index')\n",
    "meta_classifier_ds = faces_dataset.FaceMIDataset(dfs_total, target_column_name='target')\n",
    "meta_classifier_dl = DataLoader(dataset=meta_classifier_ds, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "mi_model = face_models.FaceMIModel(input_size=40, output_size=1)\n",
    "mi_model = mi_model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mi_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    epoch_loss = 0.0\n",
    "    num_correct_epoch = 0\n",
    "    time_ones = 0\n",
    "    print(f\"Train Epoch {epoch + 1}\")\n",
    "    for model_inputs, label in tqdm(meta_classifier_dl):\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = mi_model(model_inputs).round()\n",
    "\n",
    "        num_correct_epoch += (preds.round() == label).sum()\n",
    "        time_ones += preds.round().sum()\n",
    "\n",
    "        loss = criterion(preds, label)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} loss: {epoch_loss:.5f}, Acc: {num_correct_epoch / len(meta_classifier_ds):.5f}\")\n",
    "    print(f\"Predicted Label One {time_ones} times and Label Zero {len(meta_classifier_ds) - time_ones} times\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T13:48:06.510589Z",
     "end_time": "2023-08-03T14:11:21.503902Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1\n",
      "Epoch  1, Loss: 0.62066, Acc: 0.63156\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 2\n",
      "Epoch  2, Loss: 0.60432, Acc: 0.63305\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 3\n",
      "Epoch  3, Loss: 0.59771, Acc: 0.63365\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 4\n",
      "Epoch  4, Loss: 0.59338, Acc: 0.63422\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 5\n",
      "Epoch  5, Loss: 0.58996, Acc: 0.63450\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 6\n",
      "Epoch  6, Loss: 0.58721, Acc: 0.63523\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 7\n",
      "Epoch  7, Loss: 0.58454, Acc: 0.63624\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 8\n",
      "Epoch  8, Loss: 0.58256, Acc: 0.63709\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 9\n",
      "Epoch  9, Loss: 0.58072, Acc: 0.63718\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n",
      "Train Epoch 10\n",
      "Epoch 10, Loss: 0.57890, Acc: 0.63834\n",
      "Predicted Label One 0 times and Label Zero 1215594 times\n"
     ]
    }
   ],
   "source": [
    "#Large Mi Model\n",
    "dfs_total = pd.read_csv(path_configs.FACE_MI_DATA)\n",
    "if \"index\" in dfs_total:\n",
    "    dfs_total = dfs_total.drop(columns='index')\n",
    "meta_classifier_ds = faces_dataset.FaceMIDataset(dfs_total, target_column_name='target')\n",
    "meta_classifier_dl = DataLoader(dataset=meta_classifier_ds, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "mi_model_large = face_models.FaceMIModelLarge(input_size=40, output_size=1)\n",
    "mi_model_large = mi_model_large.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mi_model_large.parameters(), lr=0.003)\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    num_correct_epoch = 0\n",
    "    time_ones = 0\n",
    "    print(f\"Train Epoch {epoch + 1}\")\n",
    "    for model_inputs, label in meta_classifier_dl:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = mi_model_large(model_inputs)\n",
    "        loss = criterion(preds, label)\n",
    "        loss.backward()\n",
    "\n",
    "        time_ones += preds.round().sum()\n",
    "        epoch_loss += loss.item()\n",
    "        num_correct_epoch += (preds.round() == label).sum()\n",
    "\n",
    "        optimizer.step()\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1:2}, Loss: {epoch_loss / len(meta_classifier_dl):.5f}, Acc: {num_correct_epoch / len(meta_classifier_ds):.5f}\")\n",
    "    #print(f\"Predicted Label One {time_ones} times and Label Zero {len(meta_classifier_ds) - time_ones} times\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:11:21.508903Z",
     "end_time": "2023-08-03T14:19:17.569019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "##Build Dataset for MI Attack on Model\n",
    "#1000 Elements from Train and 1000 from Test\n",
    "mi_attack_ds = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\", transform=data_augmentation_test,\n",
    "                                          custom_range=list(range(1, 1_001)) + list(range(201_600, 202_600)))\n",
    "mi_attack_dl = DataLoader(\n",
    "    dataset=mi_attack_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "\n",
    "def create_dataset_for_mi_attack(model) -> pd.DataFrame:\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    df_epochs = []\n",
    "    for model_inputs, _ in mi_attack_dl:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        preds = model(model_inputs)\n",
    "        preds_df = pd.DataFrame(preds.cpu().detach().numpy())\n",
    "        df_epochs.append(preds_df)\n",
    "    df_epochs = pd.concat(df_epochs)\n",
    "    df_epochs['target'] = [1 if index in range(0, 1_000) else 0 for index in range(0, 2_000)]\n",
    "    return df_epochs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:22:27.392071Z",
     "end_time": "2023-08-03T14:22:30.585058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "##Evaluate MI Attack\n",
    "def eval_mi_attack(df_mi_data, model_mi_attack=mi_model) -> float:\n",
    "    mi_eval_ds = faces_dataset.FaceMIDataset(df=df_mi_data, target_column_name='target')\n",
    "    mi_eval_dl = DataLoader(dataset=mi_eval_ds,\n",
    "                            batch_size=128,\n",
    "                            shuffle=False,\n",
    "                            num_workers=8)\n",
    "\n",
    "    time_ones = 0\n",
    "    num_correct_included = 0.0\n",
    "    for inputs_pred, labels_included in mi_eval_dl:\n",
    "        inputs_pred = inputs_pred.to(device)\n",
    "        labels_included = labels_included.to(device)\n",
    "        outputs = model_mi_attack(inputs_pred)\n",
    "        num_correct_included += (outputs.round() == labels_included).sum()\n",
    "        time_ones += int(outputs.round().sum())\n",
    "    accuracy_mi = num_correct_included / len(mi_eval_ds)\n",
    "    print(f\"Accuracy MI:{accuracy_mi:.5f}, Predicted Label One {time_ones} times\")\n",
    "    return accuracy_mi\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:22:30.588058Z",
     "end_time": "2023-08-03T14:22:30.677059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "#MI Attack against Base Model\n",
    "def mi_attack(model_to_attack, model_for_mi) -> float:\n",
    "    df = create_dataset_for_mi_attack(model_to_attack)\n",
    "    return eval_mi_attack(df, model_mi_attack=model_for_mi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:22:30.679060Z",
     "end_time": "2023-08-03T14:22:30.785282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MI:0.50350, Predicted Label One 1721 times\n",
      "Accuracy MI:0.49950, Predicted Label One 1705 times\n"
     ]
    }
   ],
   "source": [
    "acc = mi_attack(model_base_all_attributes, mi_model)\n",
    "acc_large = mi_attack(model_base_all_attributes, mi_model_large)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:22:30.774065Z",
     "end_time": "2023-08-03T14:23:53.549168Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Inversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "White Box Model Inversion (Reconstruction Attack)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Create Copy of the base model (which we will attack)\n",
    "model_base = face_models.get_FaceModelBase(40)\n",
    "model_base.load_state_dict(torch.load(path_configs.FACE_BASE_MODEL))\n",
    "model_base = model_base.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T19:52:28.688558Z",
     "end_time": "2023-08-03T19:52:29.218807Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use 3 start tensors and try to recreate an image, with the labels from the first image.\n",
    "The first tensor is a random initialized one, the second has all values initialized to 0.5. The last tensor is already an image, which looks quite similar to the target labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "transform_model_inversion = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),  # Resize is done by model\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "model_inversion_start_tensors = faces_dataset.FacesDataset(label_cols='all', mode=\"custom\",\n",
    "                                                           transform=data_augmentation_test,\n",
    "                                                           custom_range=list(range(1, 2)) + list(range(202576, 202577)))\n",
    "\n",
    "#Target\n",
    "target_label = model_inversion_start_tensors[0][1].unsqueeze(0).to(device)\n",
    "\n",
    "#Start tensors\n",
    "tensor1 = torch.rand([3, 224, 224], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "tensor2 = torch.zeros([3, 224, 224], dtype=torch.float, device=device).unsqueeze(0) + 0.5\n",
    "tensor3 = model_inversion_start_tensors[1][0].to(device).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T21:57:43.028990Z",
     "end_time": "2023-08-03T21:57:46.175987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "def reconstruktion_attack(model: torchvision.models.resnet.ResNet, tensor: torch.Tensor, target: torch.Tensor,\n",
    "                          learning_rate: float = 0.0001, num_epochs: int = 10_000, optimizer_rec=\"adam\") -> torch.Tensor:\n",
    "    tensor.requires_grad = True  #Should be true since we update the tensor according to its gradients\n",
    "    optimizer_rec=torch.optim.Adam([tensor], lr=learning_rate) if optimizer_rec==\"adam\" else torch.optim.SGD([tensor],lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer_rec.zero_grad()\n",
    "        output = model(tensor)\n",
    "        loss = nn.BCELoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer_rec.step()\n",
    "\n",
    "    tensor.require_grad = False\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T21:58:11.829229Z",
     "end_time": "2023-08-03T21:58:11.921227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# tensor1 = reconstruktion_attack(model=model_base, tensor=tensor1, target=target_label)\n",
    "# tensor2 = reconstruktion_attack(model=model_base, tensor=tensor2, target=target_label)\n",
    "tensor3 = reconstruktion_attack(model=model_base, tensor=tensor3, target=target_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T21:58:12.671342Z",
     "end_time": "2023-08-03T21:59:24.649591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "# torchvision.transforms.ToPILImage()(tensor1[0]).show()\n",
    "# torchvision.transforms.ToPILImage()(tensor2[0]).show()\n",
    "torchvision.transforms.ToPILImage()(tensor3[0]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T21:59:24.665594Z",
     "end_time": "2023-08-03T21:59:28.137014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True]], device='cuda:0')"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base(tensor3).round() == target_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T22:00:33.815828Z",
     "end_time": "2023-08-03T22:00:33.914829Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
