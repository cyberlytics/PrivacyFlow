{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experimente - Datensatz Gesichter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings und Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#autoreload other packages when code changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:10:19.895257Z",
     "end_time": "2023-08-01T17:10:19.985553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)  #Reproduzierbarkeit\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.accountants import RDPAccountant\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:10:19.985553Z",
     "end_time": "2023-08-01T17:10:22.656284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Own Code\n",
    "from privacyflow.configs import path_configs\n",
    "from privacyflow.datasets import faces_dataset\n",
    "from privacyflow.models import face_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:10:22.656284Z",
     "end_time": "2023-08-01T17:10:22.750201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:10:22.750201Z",
     "end_time": "2023-08-01T17:10:22.860475Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "label_columns = 'all'  #40 attributes\n",
    "\n",
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "\n",
    "    # torchvision.transforms.Resize((224,224)), # Resize is done by model\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test = torchvision.transforms.Compose([\n",
    "    # torchvision.transforms.Resize((224,224)), # Resize is done by model\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\", transform=data_augmentation_train)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "val_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\", transform=data_augmentation_test)\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "test_dataset = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\", transform=data_augmentation_test)\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T19:28:18.772818Z",
     "end_time": "2023-08-01T19:28:27.567213Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model - Base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model_base_all_attributes = face_models.get_FaceModelBase(40).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_base_all_attributes.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T19:28:27.567213Z",
     "end_time": "2023-08-01T19:28:27.848446Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "097ec1601dfe45af89dfaefdef2d339a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader):\n\u001B[1;32m----> 6\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_inputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      9\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(5):\n",
    "    model_base_all_attributes.train()\n",
    "    epoch_loss = 0.0\n",
    "    for model_inputs, labels in tqdm(train_dataloader):\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_outputs = model_base_all_attributes(model_inputs)\n",
    "        loss = criterion(model_outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    val_loss = 0.0\n",
    "    num_corrects = 0\n",
    "    model_base_all_attributes.eval()\n",
    "    for model_inputs, labels in val_dataloader:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model_outputs = model_base_all_attributes(model_inputs)\n",
    "        loss = criterion(model_outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        num_corrects += int((model_outputs.round() == labels).sum())\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1:2}\",\n",
    "          f\"Train Loss: {epoch_loss / len(train_dataloader):.5f}\",\n",
    "          f\"Val Loss: {val_loss / len(val_dataloader):.5f}\",\n",
    "          f\"Val Accuracy (all attributes): {num_corrects / (len(val_dataset) * 40)}\"\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:10:31.224731Z",
     "end_time": "2023-08-01T17:21:32.529842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (all attributes): 0.8580315098687507\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "num_corrects = 0\n",
    "for model_inputs, labels in test_dataloader:\n",
    "    model_inputs = model_inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    model_outputs = model_base_all_attributes(model_inputs)\n",
    "    num_corrects += int((model_outputs.round() == labels).sum())\n",
    "print(f\"Test Accuracy (all attributes): {num_corrects / (len(test_dataset) * 40)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:21:32.529842Z",
     "end_time": "2023-08-01T17:23:08.656790Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Membership Inference Attacke"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Create Dataset and Dataloader for Shadow Modell\n",
    "shadow_model_ds1 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"all\", transform=data_augmentation_train)\n",
    "shadow_model_dl1 = DataLoader(dataset=shadow_model_ds1, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds2 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\", transform=data_augmentation_train)\n",
    "shadow_model_dl2 = DataLoader(dataset=shadow_model_ds2, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds3 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(1, 100_000))\n",
    "shadow_model_dl3 = DataLoader(dataset=shadow_model_ds3, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds4 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(100_000, 202_600))\n",
    "shadow_model_dl4 = DataLoader(dataset=shadow_model_ds4, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds5 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train, custom_range=range(50_000, 150_000))\n",
    "shadow_model_dl5 = DataLoader(dataset=shadow_model_ds5, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "shadow_model_ds6 = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"custom\",\n",
    "                                              transform=data_augmentation_train,\n",
    "                                              custom_range=list(range(50_000, 100_000)) + list(range(150_000, 202_600)))\n",
    "shadow_model_dl6 = DataLoader(dataset=shadow_model_ds6, batch_size=128, shuffle=True, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:23:08.656790Z",
     "end_time": "2023-08-01T17:23:24.513356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training of shadow model 1\n",
      "Epoch 1 for shadow model 1\n",
      "Finished training of shadow model 1\n",
      "Start training of shadow model 2\n",
      "Epoch 1 for shadow model 2\n",
      "Finished training of shadow model 2\n",
      "Start training of shadow model 3\n",
      "Epoch 1 for shadow model 3\n",
      "Finished training of shadow model 3\n",
      "Start training of shadow model 4\n",
      "Epoch 1 for shadow model 4\n",
      "Finished training of shadow model 4\n",
      "Start training of shadow model 5\n",
      "Epoch 1 for shadow model 5\n",
      "Finished training of shadow model 5\n",
      "Start training of shadow model 6\n",
      "Epoch 1 for shadow model 6\n",
      "Finished training of shadow model 6\n"
     ]
    }
   ],
   "source": [
    "#Train Shadow Models\n",
    "shadow_models = []\n",
    "for i,datal in enumerate([shadow_model_dl1, shadow_model_dl2, shadow_model_dl3,\n",
    "              shadow_model_dl4, shadow_model_dl5, shadow_model_dl6]):\n",
    "    print(f\"Start training of shadow model {i+1}\")\n",
    "    shadow_model = face_models.get_FaceModelBase(40).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(shadow_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        #print(f\"Epoch {epoch+1} for shadow model {i+1}\")\n",
    "        for model_inputs,labels in datal:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model_outputs = shadow_model(model_inputs)\n",
    "            loss = criterion(model_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    shadow_models.append(shadow_model)\n",
    "    #print(f\"Finished training of shadow model {i+1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T17:23:24.513356Z",
     "end_time": "2023-08-01T18:09:11.668950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Create Dataset for meta classifier\n",
    "#Datasets with included datapoints\n",
    "included_ranges = [\n",
    "    range(1,202_600), #used in shadow_model_1\n",
    "    range(1,162_771), #used in shadow_model_2\n",
    "    range(1,100_000), #used in shadow_model_3\n",
    "    range(100_000,202_600), #used in shadow_model_4\n",
    "    range(50_000,150_000), #used in shadow_model_5\n",
    "    list(range(50_000,100_000))+list(range(100_000,150_000)), #used in shadow_model_6\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T18:09:11.671951Z",
     "end_time": "2023-08-01T18:09:11.817664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start getting data from shadow model 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m shadow_model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     17\u001B[0m dfs_batches \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs,labels \u001B[38;5;129;01min\u001B[39;00m dl:\n\u001B[0;32m     19\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     20\u001B[0m     preds \u001B[38;5;241m=\u001B[39m shadow_model(model_inputs)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[0;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\connection.py:262\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\connection.py:335\u001B[0m, in \u001B[0;36mPipeConnection._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_empty_message \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    333\u001B[0m             _winapi\u001B[38;5;241m.\u001B[39mPeekNamedPipe(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\connection.py:884\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(object_list, timeout)\u001B[0m\n\u001B[0;32m    881\u001B[0m                 ready_objects\u001B[38;5;241m.\u001B[39madd(o)\n\u001B[0;32m    882\u001B[0m                 timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 884\u001B[0m     ready_handles \u001B[38;5;241m=\u001B[39m \u001B[43m_exhaustive_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwaithandle_to_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;66;03m# request that overlapped reads stop\u001B[39;00m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ov \u001B[38;5;129;01min\u001B[39;00m ov_list:\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\connection.py:816\u001B[0m, in \u001B[0;36m_exhaustive_wait\u001B[1;34m(handles, timeout)\u001B[0m\n\u001B[0;32m    814\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m L:\n\u001B[1;32m--> 816\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_winapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWaitForMultipleObjects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    817\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m WAIT_TIMEOUT:\n\u001B[0;32m    818\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Create Dataset for meta classifier\n",
    "#get distributions from shadow models\n",
    "\n",
    "dfs_total = []\n",
    "ds = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"all\", transform=data_augmentation_test)\n",
    "dl = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "for index, (shadow_model, included_range) in enumerate(zip(shadow_models, included_ranges)):\n",
    "    print(f\"Start getting data from shadow model 1\")\n",
    "    shadow_model = shadow_model.to(device)\n",
    "    shadow_model.eval()\n",
    "    dfs_batches = []\n",
    "    for model_inputs,labels in dl:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        preds = shadow_model(model_inputs)\n",
    "        preds_df = pd.DataFrame(preds.cpu().detach().numpy())\n",
    "        dfs_batches.append(preds_df)\n",
    "    df_epoch = pd.concat(dfs_batches)\n",
    "    df_epoch['target'] = [1 if index in included_range else 0 for index in range(1,202_600)]\n",
    "    dfs_total.append(df_epoch)\n",
    "\n",
    "dfs_total = pd.concat(dfs_total).reset_index()\n",
    "dfs_total.to_csv(path_configs.FACE_MI_DATA, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T18:14:41.715057Z",
     "end_time": "2023-08-01T18:14:54.906965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train meta classifier\n",
    "meta_classifier_ds = faces_dataset.FaceMIDataset(dfs_total, target_column_name='target')\n",
    "meta_classifier_dl = DataLoader(dataset=meta_classifier_ds,batch_size=128,shuffle=False)\n",
    "\n",
    "mi_model = face_models.FaceMIModel(input_size=40, output_size=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mi_model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for model_inputs,label in meta_classifier_dl:\n",
    "        model_inputs.to(device)\n",
    "        label.to(device)\n",
    "\n",
    "        preds = mi_model(model_inputs)\n",
    "        loss = criterion(preds,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
