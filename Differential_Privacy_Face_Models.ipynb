{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Differential Privacy for Vision Tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings und Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "import opacus\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#autoreload other packages when code changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:36:35.096720Z",
     "end_time": "2023-08-09T23:36:37.618111Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(20)  #Reproduzierbarkeit\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:36:37.597111Z",
     "end_time": "2023-08-09T23:36:38.157113Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Own Code\n",
    "from privacyflow.configs import path_configs\n",
    "from privacyflow.datasets import faces_dataset\n",
    "from privacyflow.models import face_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:36:38.159114Z",
     "end_time": "2023-08-09T23:36:38.471114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:36:38.527113Z",
     "end_time": "2023-08-09T23:36:38.642113Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "label_columns = 'all'  #40 attributes\n",
    "\n",
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_augmentation_train_with_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test_with_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",transform=data_augmentation_train)\n",
    "val_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\", transform=data_augmentation_test)\n",
    "test_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\", transform=data_augmentation_test)\n",
    "\n",
    "train_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",transform=data_augmentation_train_with_resize)\n",
    "val_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\",transform=data_augmentation_test_with_resize)\n",
    "test_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\",transform=data_augmentation_test_with_resize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:36:43.115845Z",
     "end_time": "2023-08-09T23:36:59.397542Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model - Base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def load_saved_model(model_type:str = \"cnn\", alt_path:str= None):\n",
    "    if model_type == \"cnn\":\n",
    "        model = face_models.get_FaceModelResNet(40)\n",
    "        path = path_configs.FACE_BASE_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "\n",
    "    elif model_type == \"transformer\":\n",
    "        model = face_models.get_FaceVisionTransformer(40)\n",
    "        path = path_configs.FACE_VIT_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "\n",
    "    elif model_type == \"dense\":\n",
    "        model = face_models.get_FaceModelDenseNet(40)\n",
    "        path = path_configs.FACE_DENSE_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:38:34.182064Z",
     "end_time": "2023-08-09T23:38:34.350064Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_model(model:nn.Module,\n",
    "                criterion:nn.Module,\n",
    "                optimizer:torch.optim.Optimizer,\n",
    "                epochs:int,\n",
    "                train_ds:torch.utils.data.Dataset,\n",
    "                val_ds:torch.utils.data.Dataset,\n",
    "                batch_size:int =32,\n",
    "                num_workers:int=0,\n",
    "                amount_labels:int=40,\n",
    "                val:bool=True):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for model_inputs, labels in tqdm(train_dl):\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model_outputs = model(model_inputs)\n",
    "            loss = criterion(model_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch: {epoch + 1:2}\",\n",
    "              f\"Train Loss: {epoch_loss / len(train_dl):.5f}\")\n",
    "\n",
    "        if val:\n",
    "            torch.cuda.empty_cache()\n",
    "            val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n",
    "            val_loss = 0.0\n",
    "            num_corrects = 0\n",
    "            model.eval()\n",
    "            for model_inputs, labels in val_dl:\n",
    "                model_inputs = model_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model_outputs = model(model_inputs)\n",
    "                loss = criterion(model_outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                num_corrects += int((model_outputs.round() == labels).sum())\n",
    "            print(f\"Val Loss: {val_loss / len(val_dl):.5f}\",\n",
    "                  f\"Val Accuracy (all attributes): {num_corrects / (len(val_ds) * amount_labels)}\")\n",
    "\n",
    "\n",
    "def test_model(model:nn.Module,\n",
    "               test_ds:torch.utils.data.Dataset,\n",
    "               batch_size:int,\n",
    "               num_workers:int =0,\n",
    "               amount_labels=40):\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size,num_workers=num_workers,shuffle=False)\n",
    "    model.eval()\n",
    "    num_corrects = 0\n",
    "    for model_inputs, labels in tqdm(test_dl):\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model_outputs = model(model_inputs)\n",
    "        num_corrects += int((model_outputs.round() == labels).sum())\n",
    "    print(f\"Test Accuracy (all attributes): {num_corrects / (len(test_ds) * amount_labels)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./privacyflow/models_trained/face_vit_np_model.pl\n",
      "<class 'torchvision.models.vision_transformer.VisionTransformer'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2496 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05455ecffcca4daf872fe1fb972c28ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (all attributes): 0.8046876565474401\n"
     ]
    }
   ],
   "source": [
    "model_vit_base_np = load_saved_model(\"transformer\", alt_path=path_configs.FACE_VIT_NP_MODEL)\n",
    "test_model(model=model_vit_base_np, test_ds=test_dataset_vit, batch_size=8,num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T23:39:13.798457Z",
     "end_time": "2023-08-09T23:46:42.862784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/156 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e25ff4b4e697497cb105620384d2183a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (all attributes): 0.5497344955415289\n"
     ]
    }
   ],
   "source": [
    "#ResNet not pretrained\n",
    "model_cnn_base_np = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_base_np.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_cnn_base_np,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=20,\n",
    "            train_ds=train_dataset_cnn,\n",
    "            val_ds=val_dataset_cnn,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            amount_labels=40)\n",
    "\n",
    "test_model(model=model_cnn_base_np, test_ds=test_dataset_cnn, batch_size=128, num_workers=8)\n",
    "#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/636 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b77609ee04834aab97f4bc1e6ddfe177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCELoss()\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model_cnn_base\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_cnn_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader_cnn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mval_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataloader_cnn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlen_val_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_dataset_cnn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mamount_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m test_model(model\u001B[38;5;241m=\u001B[39mmodel_cnn_base, test_dl\u001B[38;5;241m=\u001B[39mtest_dataloader_cnn, len_test_ds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_dataset_cnn))\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 13\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, criterion, optimizer, epochs, train_dl, val_dl, len_val_ds, amount_labels, val)\u001B[0m\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     12\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     14\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     15\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#ResNet\n",
    "model_cnn_base = face_models.get_FaceModelResNet(40).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_base.fc.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_cnn_base,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=2,\n",
    "            train_ds=train_dataset_cnn,\n",
    "            val_ds=val_dataset_cnn,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            amount_labels=40)\n",
    "\n",
    "test_model(model=model_cnn_base, test_ds=test_dataset_cnn, batch_size=128, num_workers=8)\n",
    "#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vision Transformer\n",
    "model_vit_base = face_models.get_FaceVisionTransformer(40).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_vit_base.heads.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_vit_base,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=2,\n",
    "            train_ds=train_dataset_vit,\n",
    "            val_ds=train_dataset_vit,\n",
    "            batch_size=32,\n",
    "            num_workers=8,\n",
    "            amount_labels=40,\n",
    "            val=False)\n",
    "\n",
    "test_model(model=model_vit_base, test_ds=test_dataset_vit, batch_size=128,num_workers=8)\n",
    "#torch.save(model_vit_base.state_dict(), path_configs.FACE_VIT_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5087 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535851ff9a734b9d83a9213523ae4758"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Train Loss: 0.43196\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5087 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8606164181364afb8659a108e8e1e4b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Train Loss: 0.42626\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5087 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ee57887fb964903a21330ed91867bba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Train Loss: 0.42481\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5087 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb42fe92c1124fa68ef73d0394a3629c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Train Loss: 0.42426\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5087 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de317f8f6e074ef897eaf57217db040d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCELoss()\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model_vit_base_np\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_vit_base_np\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset_vit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mval_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset_vit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43mamount_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m test_model(model\u001B[38;5;241m=\u001B[39mmodel_vit_base_np, test_ds\u001B[38;5;241m=\u001B[39mtest_dataset_vit, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#torch.save(model_vit_base.state_dict(), path_configs.FACE_VIT_MODEL)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 16\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, criterion, optimizer, epochs, train_ds, val_ds, batch_size, num_workers, amount_labels, val)\u001B[0m\n\u001B[0;32m     14\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     15\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     17\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     18\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Vision Transformer not pretrained\n",
    "model_vit_base_np = face_models.get_FaceVisionTransformer(40,pretrained=False).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_vit_base_np.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_vit_base_np,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=6,\n",
    "            train_ds=train_dataset_vit,\n",
    "            val_ds=train_dataset_vit,\n",
    "            batch_size=32,\n",
    "            num_workers=4,\n",
    "            amount_labels=40,\n",
    "            val=False)\n",
    "\n",
    "test_model(model=model_vit_base_np, test_ds=test_dataset_vit, batch_size=128,num_workers=8)\n",
    "#torch.save(model_vit_base.state_dict(), path_configs.FACE_VIT_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model + DP-SGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def train_model_dpsgd(model:nn.Module,\n",
    "                criterion:nn.Module,\n",
    "                optimizer:torch.optim.Optimizer,\n",
    "                train_dl:torch.utils.data.DataLoader,\n",
    "                privacy_engine:opacus.PrivacyEngine,\n",
    "                val_dl:torch.utils.data.DataLoader = None,\n",
    "                len_val_ds:int = 1,\n",
    "                epochs:int = 5,\n",
    "                amount_labels:int=40,\n",
    "                max_epsilon:int= 10,\n",
    "                val:bool=True):\n",
    "    epsilon_reached = False\n",
    "    for epoch in range(epochs):\n",
    "        if epsilon_reached:\n",
    "            break\n",
    "        print(f\"Start Training Epoch: {epoch + 1:2}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for model_inputs, labels in tqdm(train_dl):\n",
    "            try:\n",
    "                model_inputs = model_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #Forward + Backprop\n",
    "                optimizer.zero_grad()\n",
    "                model_outputs = model(model_inputs)\n",
    "                loss = criterion(model_outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                #Check if epsilon exceeds threshold after each batch\n",
    "                if max_epsilon < privacy_engine.accountant.get_epsilon(delta=1e-6):\n",
    "                    print(f\"ε Value {max_epsilon:2} reached in Epoch {epoch:2}\")\n",
    "                    epsilon_reached = True\n",
    "                    break\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "\n",
    "        print(f\"Finished Training Epoch: {epoch + 1:2}\",\n",
    "              f\"Train Loss: {epoch_loss / len(train_dl):.5f}\",\n",
    "              f\"ε:{privacy_engine.accountant.get_epsilon(delta=1e-6):.5f}\")\n",
    "\n",
    "        if val:\n",
    "            val_loss = 0.0\n",
    "            num_corrects = 0\n",
    "            model.eval()\n",
    "            for model_inputs, labels in val_dl:\n",
    "                try:\n",
    "                    model_inputs = model_inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    model_outputs = model(model_inputs)\n",
    "                    loss = criterion(model_outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    num_corrects += int((model_outputs.round() == labels).sum())\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "            print(f\"Val Loss: {val_loss / len(val_dl):.5f}\",\n",
    "                  f\"Val Accuracy (all attributes): {num_corrects / (len_val_ds * amount_labels)}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T16:26:34.659023Z",
     "end_time": "2023-08-09T16:26:34.753015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model_cnn_dpsgd = face_models.get_FaceModelResNet(40).to(device)\n",
    "model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_dpsgd.fc.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",transform=data_augmentation_train)\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_dataset_cnn,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "privacy_engine= PrivacyEngine()\n",
    "model_cnn_dpsgd, optimizer, train_dl = privacy_engine.make_private(\n",
    "    module=model_cnn_dpsgd,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dl,\n",
    "    noise_multiplier=1.0, #Wie viel Rauschen wird hinzugefügt - Höher = weniger Rauschen\n",
    "    max_grad_norm=1.0 #Gradienten größer als dieser Wert werden geclippt\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_model_dpsgd(model=model_cnn_dpsgd,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  train_dl=train_dl,\n",
    "                  privacy_engine=privacy_engine,\n",
    "                  max_epsilon=1,\n",
    "                  epochs=10,\n",
    "                  val=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20347 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e2116f4db3549698521958c1380b266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018844130787517545\n",
      "0.018844130787517545\n",
      "---------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model_cnn_dpsgd\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m dp_inputs,labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m             last_eps \u001B[38;5;241m=\u001B[39m privacy_engine\u001B[38;5;241m.\u001B[39maccountant\u001B[38;5;241m.\u001B[39mget_epsilon(delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:54\u001B[0m, in \u001B[0;36mFacesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     52\u001B[0m image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_range[idx]\n\u001B[0;32m     53\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_image(image_id)\n\u001B[1;32m---> 54\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:66\u001B[0m, in \u001B[0;36mFacesDataset._load_label\u001B[1;34m(self, img_id)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_label\u001B[39m(\u001B[38;5;28mself\u001B[39m, img_id):\n\u001B[1;32m---> 66\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mimg_id\u001B[49m\u001B[38;5;132;43;01m:\u001B[39;49;00m\u001B[38;5;124;43m06d\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     67\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(labels, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1100\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1102\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1325\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_slice_axis(key, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_bool_indexer(key):\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getbool_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like_indexer(key):\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;66;03m# an iterable multi-selection\u001B[39;00m\n\u001B[0;32m   1328\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(labels, MultiIndex)):\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1122\u001B[0m, in \u001B[0;36m_LocationIndexer._getbool_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1120\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1121\u001B[0m key \u001B[38;5;241m=\u001B[39m check_bool_indexer(labels, key)\n\u001B[1;32m-> 1122\u001B[0m inds \u001B[38;5;241m=\u001B[39m \u001B[43mkey\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnonzero\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_take_with_is_copy(inds, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_cnn_dpsgd.train()\n",
    "for epoch in range(3):\n",
    "    for dp_inputs,labels in tqdm(train_dl):\n",
    "        try:\n",
    "            dp_inputs = dp_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model_cnn_dpsgd.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_cnn_dpsgd(dp_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except RuntimeError as error:\n",
    "            continue\n",
    "        except:\n",
    "            break\n",
    "    print(f\"Finished Training Epoch {epoch+1}\")\n",
    "    print(f\"ε Value {privacy_engine.accountant.get_epsilon(delta=1e-6):.5f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 13\u001B[0m\n\u001B[0;32m      5\u001B[0m train_dataset_cnn \u001B[38;5;241m=\u001B[39m faces_dataset\u001B[38;5;241m.\u001B[39mFacesDataset(label_cols\u001B[38;5;241m=\u001B[39mlabel_columns, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m                                                transform\u001B[38;5;241m=\u001B[39mdata_augmentation_train)\n\u001B[0;32m      7\u001B[0m train_dataloader_cnn \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m      8\u001B[0m     dataset\u001B[38;5;241m=\u001B[39mtrain_dataset_cnn,\n\u001B[0;32m      9\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m     10\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     11\u001B[0m )\n\u001B[0;32m     12\u001B[0m val_dataloader_cnn \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[1;32m---> 13\u001B[0m     dataset\u001B[38;5;241m=\u001B[39m\u001B[43mval_dataset_cnn\u001B[49m,\n\u001B[0;32m     14\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m     15\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     16\u001B[0m )\n\u001B[0;32m     17\u001B[0m test_dataloader_cnn \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m     18\u001B[0m     dataset\u001B[38;5;241m=\u001B[39mtest_dataset_cnn,\n\u001B[0;32m     19\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m     20\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     21\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val_dataset_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",\n",
    "                                               transform=data_augmentation_train)\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\",\n",
    "                                               transform=data_augmentation_train)\n",
    "train_dataloader_cnn = DataLoader(\n",
    "    dataset=train_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader_cnn = DataLoader(\n",
    "    dataset=val_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "test_dataloader_cnn = DataLoader(\n",
    "    dataset=test_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T11:08:25.927884Z",
     "end_time": "2023-08-08T11:08:28.847729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40693 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27db7510cf5249e6ac552cc4f1f2b952"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCELoss()\n\u001B[0;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model_cnn_dpsgd\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mtrain_model_dpsgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_cnn_dpsgd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnoise_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader_cnn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mamount_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43mval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#test_model(model=model_cnn_base, test_dl=test_dataloader_cnn, len_test_ds=len(test_dataset_cnn))\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[22], line 24\u001B[0m, in \u001B[0;36mtrain_model_dpsgd\u001B[1;34m(model, criterion, optimizer, epochs, noise_multiplier, train_dl, val_dl, len_val_ds, amount_labels, max_epsilon, val)\u001B[0m\n\u001B[0;32m     22\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     23\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     26\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:54\u001B[0m, in \u001B[0;36mFacesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     52\u001B[0m image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_range[idx]\n\u001B[0;32m     53\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_image(image_id)\n\u001B[1;32m---> 54\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:66\u001B[0m, in \u001B[0;36mFacesDataset._load_label\u001B[1;34m(self, img_id)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_label\u001B[39m(\u001B[38;5;28mself\u001B[39m, img_id):\n\u001B[1;32m---> 66\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mimg_id\u001B[49m\u001B[38;5;132;43;01m:\u001B[39;49;00m\u001B[38;5;124;43m06d\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     67\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(labels, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1100\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1102\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1325\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_slice_axis(key, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_bool_indexer(key):\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getbool_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like_indexer(key):\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;66;03m# an iterable multi-selection\u001B[39;00m\n\u001B[0;32m   1328\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(labels, MultiIndex)):\n",
      "File \u001B[1;32m~\\Documents\\uni\\masterarbeit\\PrivacyFlow\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1122\u001B[0m, in \u001B[0;36m_LocationIndexer._getbool_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1120\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1121\u001B[0m key \u001B[38;5;241m=\u001B[39m check_bool_indexer(labels, key)\n\u001B[1;32m-> 1122\u001B[0m inds \u001B[38;5;241m=\u001B[39m \u001B[43mkey\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnonzero\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_take_with_is_copy(inds, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_cnn_dpsgd = face_models.get_FaceModelResNet(40).to(device)\n",
    "model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_dpsgd.fc.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "#test_model(model=model_cnn_base, test_dl=test_dataloader_cnn, len_test_ds=len(test_dataset_cnn))\n",
    "\n",
    "#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T01:24:16.865571Z",
     "end_time": "2023-08-08T01:24:32.861798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
