{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Differential Privacy for Vision Tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings und Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "import opacus\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#autoreload other packages when code changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:45.535657200Z",
     "start_time": "2023-08-24T22:32:42.383837900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(20)  #Reproduzierbarkeit\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:46.191495900Z",
     "start_time": "2023-08-24T22:32:45.907275400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Own Code\n",
    "from privacyflow.configs import path_configs\n",
    "from privacyflow.datasets import faces_dataset\n",
    "from privacyflow.models import face_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:46.868635400Z",
     "start_time": "2023-08-24T22:32:46.342899900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:46.931139900Z",
     "start_time": "2023-08-24T22:32:46.866857700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_columns = 'all'  #40 attributes\n",
    "\n",
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Resize((224,224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_augmentation_train_with_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_augmentation_test_with_resize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",transform=data_augmentation_train)\n",
    "val_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\", transform=data_augmentation_test)\n",
    "test_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\", transform=data_augmentation_test)\n",
    "\n",
    "train_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",transform=data_augmentation_train_with_resize)\n",
    "val_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\",transform=data_augmentation_test_with_resize)\n",
    "test_dataset_vit = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"test\",transform=data_augmentation_test_with_resize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:55.797541Z",
     "start_time": "2023-08-24T22:32:47.902618200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models - No DP "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_saved_model(model_type:str = \"cnn\", alt_path:str= None):\n",
    "    if model_type == \"cnn\":\n",
    "        model = face_models.get_FaceModelResNet(40)\n",
    "        path = path_configs.FACE_BASE_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "\n",
    "    elif model_type == \"transformer\":\n",
    "        model = face_models.get_FaceVisionTransformer(40)\n",
    "        path = path_configs.FACE_VIT_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "\n",
    "    elif model_type == \"dense\":\n",
    "        model = face_models.get_FaceModelDenseNet(40)\n",
    "        path = path_configs.FACE_DENSE_MODEL if not alt_path else alt_path\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model = model.to(device)\n",
    "        return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:55.843728100Z",
     "start_time": "2023-08-24T22:32:55.798542300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_model(model:nn.Module,\n",
    "                criterion:nn.Module,\n",
    "                optimizer:torch.optim.Optimizer,\n",
    "                epochs:int,\n",
    "                train_ds:torch.utils.data.Dataset,\n",
    "                val_ds:torch.utils.data.Dataset,\n",
    "                batch_size:int =32,\n",
    "                num_workers:int=0,\n",
    "                amount_labels:int=40,\n",
    "                val:bool=True):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for model_inputs, labels in tqdm(train_dl, leave=False):\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model_outputs = model(model_inputs)\n",
    "            loss = criterion(model_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch: {epoch + 1:2}\",\n",
    "              f\"Train Loss: {epoch_loss / len(train_dl):.5f}\")\n",
    "\n",
    "        if val:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect() #free cuda memory from train_dataloader\n",
    "            val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n",
    "            val_loss = 0.0\n",
    "            num_corrects = 0\n",
    "            model.eval()\n",
    "            for model_inputs, labels in val_dl:\n",
    "                model_inputs = model_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model_outputs = model(model_inputs)\n",
    "                loss = criterion(model_outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                num_corrects += int((model_outputs.round() == labels).sum())\n",
    "            print(f\"Val Loss: {val_loss / len(val_dl):.5f}\",\n",
    "                  f\"Val Accuracy (all attributes): {num_corrects / (len(val_ds) * amount_labels)}\")\n",
    "\n",
    "\n",
    "def test_model(model:nn.Module,\n",
    "               test_ds:torch.utils.data.Dataset,\n",
    "               batch_size:int,\n",
    "               num_workers:int =0,\n",
    "               amount_labels=40):\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size,num_workers=num_workers,shuffle=False)\n",
    "    model.eval()\n",
    "    num_corrects = 0\n",
    "    for model_inputs, labels in tqdm(test_dl):\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model_outputs = model(model_inputs)\n",
    "        num_corrects += int((model_outputs.round() == labels).sum())\n",
    "    print(f\"Test Accuracy (all attributes): {num_corrects / (len(test_ds) * amount_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:55.896630400Z",
     "start_time": "2023-08-24T22:32:55.843728100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ResNet not pretrained\n",
    "model_cnn_base_np = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_base_np.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_cnn_base_np,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=12,\n",
    "            train_ds=train_dataset_cnn,\n",
    "            val_ds=val_dataset_cnn,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            amount_labels=40,\n",
    "            val=True)\n",
    "\n",
    "# test_model(model=model_cnn_base_np, test_ds=test_dataset_cnn, batch_size=128, num_workers=8)\n",
    "torch.save(model_cnn_base_np.state_dict(), path_configs.FACE_BASE_MODEL)\n",
    "model_cnn_base_np.to(torch.device(\"cpu\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ResNet\n",
    "model_cnn_base = face_models.get_FaceModelResNet(40).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_base.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_cnn_base,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=4,\n",
    "            train_ds=train_dataset_cnn,\n",
    "            val_ds=val_dataset_cnn,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            amount_labels=40)\n",
    "\n",
    "test_model(model=model_cnn_base, test_ds=test_dataset_cnn, batch_size=128, num_workers=8)\n",
    "torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vision Transformer\n",
    "model_vit_base = face_models.get_FaceVisionTransformer(40).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_vit_base.heads.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_vit_base,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=3,\n",
    "            train_ds=train_dataset_vit,\n",
    "            val_ds=train_dataset_vit,\n",
    "            batch_size=64,\n",
    "            num_workers=8,\n",
    "            amount_labels=40)\n",
    "\n",
    "torch.save(model_vit_base.state_dict(), path_configs.FACE_VIT_MODEL)\n",
    "test_model(model=model_vit_base, test_ds=test_dataset_vit, batch_size=64,num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T10:41:38.843642400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Vision Transformer not pretrained\n",
    "model_vit_base_np = face_models.get_FaceVisionTransformer(40,pretrained=False).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_vit_base_np.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model=model_vit_base_np,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epochs=15,\n",
    "            train_ds=train_dataset_vit,\n",
    "            val_ds=train_dataset_vit,\n",
    "            batch_size=128,\n",
    "            num_workers=8,\n",
    "            amount_labels=40,\n",
    "            val=False)\n",
    "\n",
    "\n",
    "torch.save(model_vit_base_np.state_dict(), path_configs.FACE_VIT_NP_MODEL)\n",
    "test_model(model=model_vit_base_np, test_ds=test_dataset_vit, batch_size=64,num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model + DP-SGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_model_dpsgd(model:nn.Module,\n",
    "                criterion:nn.Module,\n",
    "                optimizer:torch.optim.Optimizer,\n",
    "                train_dl:torch.utils.data.DataLoader,\n",
    "                privacy_engine:opacus.PrivacyEngine,\n",
    "                val_dl:torch.utils.data.DataLoader = None,\n",
    "                len_val_ds:int = 1,\n",
    "                epochs:int = 5,\n",
    "                amount_labels:int=40,\n",
    "                max_epsilon:int= 10,\n",
    "                val:bool=True):\n",
    "    epsilon_reached = False\n",
    "    for epoch in range(epochs):\n",
    "        if epsilon_reached:\n",
    "            break\n",
    "        print(f\"Start Training Epoch: {epoch + 1:2}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for model_inputs, labels in tqdm(train_dl):\n",
    "            try:\n",
    "                model_inputs = model_inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #Forward + Backprop\n",
    "                optimizer.zero_grad()\n",
    "                model_outputs = model(model_inputs)\n",
    "                loss = criterion(model_outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                #Check if epsilon exceeds threshold after each batch\n",
    "                if max_epsilon < privacy_engine.accountant.get_epsilon(delta=1e-6):\n",
    "                    print(f\"ε Value {max_epsilon:2} reached in Epoch {epoch:2}\")\n",
    "                    epsilon_reached = True\n",
    "                    break\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "\n",
    "        print(f\"Finished Training Epoch: {epoch + 1:2}\",\n",
    "              f\"Train Loss: {epoch_loss / len(train_dl):.5f}\",\n",
    "              f\"ε:{privacy_engine.accountant.get_epsilon(delta=1e-6):.5f}\")\n",
    "\n",
    "        if val:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect() #free cuda memory from train_dataloader\n",
    "            val_loss = 0.0\n",
    "            num_corrects = 0\n",
    "            model.eval()\n",
    "            for model_inputs, labels in val_dl:\n",
    "                try:\n",
    "                    model_inputs = model_inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    model_outputs = model(model_inputs)\n",
    "                    loss = criterion(model_outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    num_corrects += int((model_outputs.round() == labels).sum())\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "            print(f\"Val Loss: {val_loss / len(val_dl):.5f}\",\n",
    "                  f\"Val Accuracy (all attributes): {num_corrects / (len_val_ds * amount_labels)}\")\n",
    "        print(\"-------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:32:59.127517600Z",
     "start_time": "2023-08-24T22:32:59.075423500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#DPSGD consumes more memory, thus we decrease the batch size\n",
    "train_dl_dpsgd = DataLoader(\n",
    "    dataset=train_dataset_cnn,\n",
    "    batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:33:37.060935500Z",
     "start_time": "2023-08-24T22:33:37.013674200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Epochs = 1 ,Noise Mult=0.44464111328125\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b56b431c74db428fba1205cd9a6955cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44759 ε:4.99686\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 3 ,Noise Mult=0.463714599609375\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0ff3c0d90f54d3bab2a182564123547"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44773 ε:4.32225\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a49f0dd36754a4eb06b4e4b8c4f7bc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  2 Train Loss: 0.45100 ε:4.72101\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3fb5148fb484a2ea2cf3b145c04c1ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  3 Train Loss: 0.45109 ε:4.99441\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 5 ,Noise Mult=0.473785400390625\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2862ce6289bd439f8bfa7b573af130c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44630 ε:4.00017\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fa46aebb17a42b9b877fcfa5b53bfbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  2 Train Loss: 0.44953 ε:4.37227\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d377498857b24c12b63356c6fff6711f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  3 Train Loss: 0.44883 ε:4.62207\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f951002f43c4235a6bb59521f1fc1dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  4 Train Loss: 0.45175 ε:4.82232\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c234db941f454951afad48be432e4303"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  5 Train Loss: 0.45369 ε:4.99541\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 10 ,Noise Mult=0.489501953125\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44aba4051bd34b7891fb7a9c89af2c20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44721 ε:3.53760\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7009009005ae4976803560e7911c6997"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  2 Train Loss: 0.45209 ε:3.87658\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cce176eff01426e8587f2e5345d47e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  3 Train Loss: 0.45461 ε:4.09807\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13623538b566478194cebe1e044974ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  4 Train Loss: 0.45551 ε:4.27209\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3012441d16143e480d1e0615e61c5c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  5 Train Loss: 0.45693 ε:4.42031\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  6\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8bfc65b909248dc9e2ff7861f2465f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  6 Train Loss: 0.45824 ε:4.55211\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3356d57d7746452d9b69f137dc23daa4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  7 Train Loss: 0.45915 ε:4.67255\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "887a138f25d94e0a890d912eb767bae7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  8 Train Loss: 0.46067 ε:4.78454\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  9\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d9ff083c668454c9b8aefed575e20d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  9 Train Loss: 0.46169 ε:4.88999\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c11cfc59c71435ab6e5d866151a77f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch: 10 Train Loss: 0.46185 ε:4.99018\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in [1,3,5,10]:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    model_cnn_dpsgd = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "    model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_cnn_dpsgd.parameters(), lr=0.01)\n",
    "    privacy_engine= PrivacyEngine()\n",
    "    model_cnn_dpsgd, optimizer, train_dl = privacy_engine.make_private_with_epsilon(\n",
    "        module=model_cnn_dpsgd,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_dl_dpsgd,\n",
    "        epochs=num_epochs,\n",
    "        target_epsilon=5,\n",
    "        target_delta=1e-6,\n",
    "        max_grad_norm=1.0 #Gradienten größer als dieser Wert werden geclippt\n",
    "    )\n",
    "    print(f\"Num Epochs = {num_epochs} ,Noise Mult={optimizer.noise_multiplier}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    train_model_dpsgd(model=model_cnn_dpsgd,\n",
    "                      criterion=criterion,\n",
    "                      optimizer=optimizer,\n",
    "                      train_dl=train_dl,\n",
    "                      privacy_engine=privacy_engine,\n",
    "                      max_epsilon=5,\n",
    "                      epochs=num_epochs,\n",
    "                      val=False)\n",
    "    torch.save(model_cnn_dpsgd.state_dict(), f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cnn_epsilon5_epochs{num_epochs}_clipp1.pl\" )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T09:53:26.119583800Z",
     "start_time": "2023-08-24T22:33:38.875979500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Epochs = 1 ,Noise Mult=0.360107421875\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8912a8d1a5c43b8b4dff3dd260fba10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44450 ε:9.99461\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 3 ,Noise Mult=0.38299560546875\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c02802abb2574c1993a307dba8829cc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44475 ε:8.13555\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf99e116753540959579efe08a1b891b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  2 Train Loss: 0.44290 ε:9.19167\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43f3200033be4b8891911d0a47cb5119"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  3 Train Loss: 0.44326 ε:9.99157\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 5 ,Noise Mult=0.394744873046875\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8759cf674ddb40a08ec9d22f977fe792"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44573 ε:7.36978\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5407119c7bef47ccbcc405cb9aece4ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  2 Train Loss: 0.44469 ε:8.25347\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30bb471a40b542f8ae89dcffd27848ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  3 Train Loss: 0.44333 ε:8.92883\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9d32677dcbe415fb80054d6ac8d2a00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  4 Train Loss: 0.44459 ε:9.49626\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b436309ca0c34ab1aad288d669d32a99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  5 Train Loss: 0.44377 ε:9.99608\n",
      "-------------------------------------------------------------\n",
      "Num Epochs = 10 ,Noise Mult=0.41229248046875\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8532d381d62417ca7cc9625d87ca527"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m     20\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect() \u001B[38;5;66;03m#free cuda memory from train_dataloader\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[43mtrain_model_dpsgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_cnn_dpsgd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mprivacy_engine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivacy_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mmax_epsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model_cnn_dpsgd\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_configs\u001B[38;5;241m.\u001B[39mMODELS_TRAINED_BASE_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/cnn_epsilon10_epochs\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_clipp1.pl\u001B[39m\u001B[38;5;124m\"\u001B[39m )\n",
      "Cell \u001B[1;32mIn[8], line 19\u001B[0m, in \u001B[0;36mtrain_model_dpsgd\u001B[1;34m(model, criterion, optimizer, train_dl, privacy_engine, val_dl, len_val_ds, epochs, amount_labels, max_epsilon, val)\u001B[0m\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     18\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\notebook.py:249\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    248\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    250\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    251\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    252\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1182\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1185\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\opacus\\data_loader.py:53\u001B[0m, in \u001B[0;36mwrap_collate_with_empty.<locals>.collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcollate\u001B[39m(batch):\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(batch) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 53\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m     56\u001B[0m             torch\u001B[38;5;241m.\u001B[39mzeros(shape, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m     57\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m shape, dtype \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sample_empty_shapes, dtypes)\n\u001B[0;32m     58\u001B[0m         ]\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[0;32m    205\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    160\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    161\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[1;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for num_epochs in [1,3,5,10]:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    model_cnn_dpsgd = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "    model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_cnn_dpsgd.parameters(), lr=0.01)\n",
    "    privacy_engine= PrivacyEngine()\n",
    "    model_cnn_dpsgd, optimizer, train_dl = privacy_engine.make_private_with_epsilon(\n",
    "        module=model_cnn_dpsgd,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_dl_dpsgd,\n",
    "        epochs=num_epochs,\n",
    "        target_epsilon=10,\n",
    "        target_delta=1e-6,\n",
    "        max_grad_norm=1.0 #Gradienten größer als dieser Wert werden geclippt\n",
    "    )\n",
    "    print(f\"Num Epochs = {num_epochs} ,Noise Mult={optimizer.noise_multiplier}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    train_model_dpsgd(model=model_cnn_dpsgd,\n",
    "                      criterion=criterion,\n",
    "                      optimizer=optimizer,\n",
    "                      train_dl=train_dl,\n",
    "                      privacy_engine=privacy_engine,\n",
    "                      max_epsilon=10,\n",
    "                      epochs=num_epochs,\n",
    "                      val=False)\n",
    "    torch.save(model_cnn_dpsgd.state_dict(), f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cnn_epsilon10_epochs{num_epochs}_clipp1.pl\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-25T15:54:51.895202500Z",
     "start_time": "2023-08-25T09:53:26.119583800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Epochs = 1 ,Noise Mult=0.631103515625\n",
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2544 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "932e9c2a078e4093b0f7eb6f608e237a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m     20\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect() \u001B[38;5;66;03m#free cuda memory from train_dataloader\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[43mtrain_model_dpsgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_cnn_dpsgd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mprivacy_engine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivacy_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mmax_epsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model_cnn_dpsgd\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_configs\u001B[38;5;241m.\u001B[39mMODELS_TRAINED_BASE_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/cnn_epochs\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_clipp0-5.pl\u001B[39m\u001B[38;5;124m\"\u001B[39m )\n",
      "Cell \u001B[1;32mIn[9], line 19\u001B[0m, in \u001B[0;36mtrain_model_dpsgd\u001B[1;34m(model, criterion, optimizer, train_dl, privacy_engine, val_dl, len_val_ds, epochs, amount_labels, max_epsilon, val)\u001B[0m\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     18\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\notebook.py:249\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    248\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    250\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    251\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    252\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1182\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1185\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:53\u001B[0m, in \u001B[0;36mFacesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     52\u001B[0m     image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_range[idx]\n\u001B[1;32m---> 53\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_label(image_id)\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:62\u001B[0m, in \u001B[0;36mFacesDataset._load_image\u001B[1;34m(self, img_id)\u001B[0m\n\u001B[0;32m     60\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(img_filename)\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[1;32m---> 62\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torchvision\\transforms\\autoaugment.py:279\u001B[0m, in \u001B[0;36mAutoAugment.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m signed \u001B[38;5;129;01mand\u001B[39;00m signs[i] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    278\u001B[0m             magnitude \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1.0\u001B[39m\n\u001B[1;32m--> 279\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43m_apply_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmagnitude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torchvision\\transforms\\autoaugment.py:77\u001B[0m, in \u001B[0;36m_apply_op\u001B[1;34m(img, op_name, magnitude, interpolation, fill)\u001B[0m\n\u001B[0;32m     75\u001B[0m     img \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39madjust_sharpness(img, \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m+\u001B[39m magnitude)\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m op_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPosterize\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 77\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmagnitude\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m op_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolarize\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     79\u001B[0m     img \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msolarize(img, magnitude)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1432\u001B[0m, in \u001B[0;36mposterize\u001B[1;34m(img, bits)\u001B[0m\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number if bits should be between 0 and 8. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m-> 1432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_pil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mposterize(img, bits)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:360\u001B[0m, in \u001B[0;36mposterize\u001B[1;34m(img, bits)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_pil_image(img):\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be PIL Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 360\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mImageOps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbits\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\PIL\\ImageOps.py:554\u001B[0m, in \u001B[0;36mposterize\u001B[1;34m(image, bits)\u001B[0m\n\u001B[0;32m    552\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m256\u001B[39m):\n\u001B[0;32m    553\u001B[0m     lut\u001B[38;5;241m.\u001B[39mappend(i \u001B[38;5;241m&\u001B[39m mask)\n\u001B[1;32m--> 554\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_lut\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlut\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\PIL\\ImageOps.py:56\u001B[0m, in \u001B[0;36m_lut\u001B[1;34m(image, lut)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m image\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lut) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m256\u001B[39m:\n\u001B[0;32m     55\u001B[0m         lut \u001B[38;5;241m=\u001B[39m lut \u001B[38;5;241m+\u001B[39m lut \u001B[38;5;241m+\u001B[39m lut\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlut\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot supported for this image mode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\PIL\\Image.py:1738\u001B[0m, in \u001B[0;36mImage.point\u001B[1;34m(self, lut, mode)\u001B[0m\n\u001B[0;32m   1714\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpoint\u001B[39m(\u001B[38;5;28mself\u001B[39m, lut, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1716\u001B[0m \u001B[38;5;124;03m    Maps this image through a lookup table or function.\u001B[39;00m\n\u001B[0;32m   1717\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[0;32m   1736\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1738\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1740\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(lut, ImagePointHandler):\n\u001B[0;32m   1741\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m lut\u001B[38;5;241m.\u001B[39mpoint(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\PIL\\ImageFile.py:260\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m    255\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage file is truncated \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    256\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(b)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m bytes not processed)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    257\u001B[0m         )\n\u001B[0;32m    259\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[1;32m--> 260\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for num_epochs in [1,3,5,10]:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    model_cnn_dpsgd = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "    model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_cnn_dpsgd.parameters(), lr=0.01)\n",
    "    privacy_engine= PrivacyEngine()\n",
    "    model_cnn_dpsgd, optimizer, train_dl = privacy_engine.make_private_with_epsilon(\n",
    "        module=model_cnn_dpsgd,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_dl_dpsgd,\n",
    "        epochs=num_epochs,\n",
    "        target_epsilon=1,\n",
    "        target_delta=1e-6,\n",
    "        max_grad_norm=0.5 #Gradienten größer als dieser Wert werden geclippt\n",
    "    )\n",
    "    print(f\"Num Epochs = {num_epochs} ,Noise Mult={optimizer.noise_multiplier}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #free cuda memory from train_dataloader\n",
    "    train_model_dpsgd(model=model_cnn_dpsgd,\n",
    "                      criterion=criterion,\n",
    "                      optimizer=optimizer,\n",
    "                      train_dl=train_dl,\n",
    "                      privacy_engine=privacy_engine,\n",
    "                      max_epsilon=1,\n",
    "                      epochs=num_epochs,\n",
    "                      val=False)\n",
    "    torch.save(model_cnn_dpsgd.state_dict(), f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cnn_epochs{num_epochs}_clipp0-5.pl\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T22:28:03.733686700Z",
     "start_time": "2023-08-24T22:25:13.814366700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "model_cnn_dpsgd = face_models.get_FaceModelResNet(40,pretrained=False).to(device)\n",
    "model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_dpsgd.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T11:50:06.570772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "privacy_engine= PrivacyEngine()\n",
    "model_cnn_dpsgd, optimizer, train_dl = privacy_engine.make_private(\n",
    "    module=model_cnn_dpsgd,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dl_dpsgd,\n",
    "    noise_multiplier=1.0, #Wie viel Rauschen wird hinzugefügt - Höher = weniger Rauschen\n",
    "    max_grad_norm=1.0 #Gradienten größer als dieser Wert werden geclippt\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T11:17:51.570070900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Epoch:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da0c136acbb944088978f5e48dccdb23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Epoch:  1 Train Loss: 0.44029 ε:0.16868\n",
      "-------------------------------------------------------------\n",
      "Start Training Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1272 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec07f59f2efa465db89f14392b97adc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_model_dpsgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_cnn_dpsgd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mprivacy_engine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivacy_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mmax_epsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 19\u001B[0m, in \u001B[0;36mtrain_model_dpsgd\u001B[1;34m(model, criterion, optimizer, train_dl, privacy_engine, val_dl, len_val_ds, epochs, amount_labels, max_epsilon, val)\u001B[0m\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     18\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dl):\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m model_inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\notebook.py:249\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    248\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    250\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    251\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    252\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\tqdm\\std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1182\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1185\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:54\u001B[0m, in \u001B[0;36mFacesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     52\u001B[0m image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_range[idx]\n\u001B[0;32m     53\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_image(image_id)\n\u001B[1;32m---> 54\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\PrivacyFlow\\privacyflow\\datasets\\faces_dataset.py:66\u001B[0m, in \u001B[0;36mFacesDataset._load_label\u001B[1;34m(self, img_id)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_label\u001B[39m(\u001B[38;5;28mself\u001B[39m, img_id):\n\u001B[1;32m---> 66\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mimg_id\u001B[49m\u001B[38;5;132;43;01m:\u001B[39;49;00m\u001B[38;5;124;43m06d\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     67\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(labels, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1100\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1102\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1325\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_slice_axis(key, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_bool_indexer(key):\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getbool_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like_indexer(key):\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;66;03m# an iterable multi-selection\u001B[39;00m\n\u001B[0;32m   1328\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(labels, MultiIndex)):\n",
      "File \u001B[1;32m~\\Documents\\masterarbeit\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1122\u001B[0m, in \u001B[0;36m_LocationIndexer._getbool_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1120\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1121\u001B[0m key \u001B[38;5;241m=\u001B[39m check_bool_indexer(labels, key)\n\u001B[1;32m-> 1122\u001B[0m inds \u001B[38;5;241m=\u001B[39m \u001B[43mkey\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnonzero\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_take_with_is_copy(inds, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_model_dpsgd(model=model_cnn_dpsgd,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  train_dl=train_dl,\n",
    "                  privacy_engine=privacy_engine,\n",
    "                  max_epsilon=1,\n",
    "                  epochs=10,\n",
    "                  val=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T11:17:52.178035400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cnn_dpsgd.train()\n",
    "for epoch in range(3):\n",
    "    for dp_inputs,labels in tqdm(train_dl):\n",
    "        try:\n",
    "            dp_inputs = dp_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model_cnn_dpsgd.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_cnn_dpsgd(dp_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except RuntimeError as error:\n",
    "            continue\n",
    "        except:\n",
    "            break\n",
    "    print(f\"Finished Training Epoch {epoch+1}\")\n",
    "    print(f\"ε Value {privacy_engine.accountant.get_epsilon(delta=1e-6):.5f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"train\",\n",
    "                                               transform=data_augmentation_train)\n",
    "\n",
    "train_dataset_cnn = faces_dataset.FacesDataset(label_cols=label_columns, mode=\"val\",\n",
    "                                               transform=data_augmentation_train)\n",
    "train_dataloader_cnn = DataLoader(\n",
    "    dataset=train_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader_cnn = DataLoader(\n",
    "    dataset=val_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "test_dataloader_cnn = DataLoader(\n",
    "    dataset=test_dataset_cnn,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cnn_dpsgd = face_models.get_FaceModelResNet(40).to(device)\n",
    "model_cnn_dpsgd = ModuleValidator.fix(model_cnn_dpsgd)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_dpsgd.fc.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "#test_model(model=model_cnn_base, test_dl=test_dataloader_cnn, len_test_ds=len(test_dataset_cnn))\n",
    "\n",
    "#torch.save(model_cnn_base.state_dict(), path_configs.FACE_BASE_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
