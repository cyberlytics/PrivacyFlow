{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Membership Inference Attack"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b07685004bdb310d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings and Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1456de55d8afb9be"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#autoreload other packages when code changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:19.003224600Z",
     "start_time": "2023-09-24T13:28:18.972096800Z"
    }
   },
   "id": "f4e326433fa5cf32"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:22.189872100Z",
     "start_time": "2023-09-24T13:28:19.007369700Z"
    }
   },
   "id": "250c79eece22d5ce"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Own Code\n",
    "from privacyflow.configs import path_configs\n",
    "from privacyflow.datasets import faces_dataset, mi_dataset\n",
    "from privacyflow.models import face_models, cifar_models, membership_inference_meta_classifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:22.237997Z",
     "start_time": "2023-09-24T13:28:22.187650600Z"
    }
   },
   "id": "c533cfe23633a828"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU will be used\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:22.316120400Z",
     "start_time": "2023-09-24T13:28:22.237997Z"
    }
   },
   "id": "9661d3ee58f7a7e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR-10 Model - Shadow Modells"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ace744cccf435d4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_dataset_train = torchvision.datasets.CIFAR10(root=path_configs.CIFAR_FOLDER_PATH,\n",
    "                                                     transform=torchvision.transforms.Compose(\n",
    "                                                         [torchvision.transforms.ToTensor()]\n",
    "                                                     ),\n",
    "                                                     train=True,\n",
    "                                                     download=True)\n",
    "\n",
    "cifar10_dataset_test = torchvision.datasets.CIFAR10(root=path_configs.CIFAR_FOLDER_PATH,\n",
    "                                                    transform=torchvision.transforms.Compose(\n",
    "                                                        [torchvision.transforms.ToTensor()]\n",
    "                                                    ),\n",
    "                                                    train=False,\n",
    "                                                    download=True)\n",
    "\n",
    "#Combine the datasets for the usage for the shadow models\n",
    "cifar10_dataset = torch.utils.data.ConcatDataset([cifar10_dataset_train, cifar10_dataset_test])\n",
    "\n",
    "#Sample the train dataset to only have 10000 items, which matches the number of items in test data\n",
    "indices = random.sample(range(50000),10000)\n",
    "cifar10_dataset_train_reduced = torch.utils.data.Subset(cifar10_dataset_train,indices=indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:23.350120200Z",
     "start_time": "2023-09-24T13:28:22.316120400Z"
    }
   },
   "id": "8a4660c8af470aba"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_model_no_logs(model: nn.Module,\n",
    "                        train_dl: torch.utils.data.DataLoader,\n",
    "                        optimizer: torch.optim,\n",
    "                        criterion: nn.Module,\n",
    "                        num_epochs: int = 15):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        for model_inputs, labels in train_dl:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            model_outputs = model(model_inputs)\n",
    "            loss = criterion(model_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T13:28:32.029082400Z",
     "start_time": "2023-09-24T13:28:31.982210600Z"
    }
   },
   "id": "b76b1570a0e71e87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_mi_data(model: nn.Module,\n",
    "                datal: torch.utils.data.DataLoader,\n",
    "                label_included: bool,\n",
    "                apply_softmax: bool = True):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    dfs_batches = []\n",
    "    for model_inputs, _ in datal:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        preds = model(model_inputs)\n",
    "        if apply_softmax:\n",
    "            preds = torch.softmax(preds, dim=-1)\n",
    "        dfs_batches.append(pd.DataFrame(preds.cpu().detach().numpy()))\n",
    "    dfs_batches = pd.concat(dfs_batches)\n",
    "    dfs_batches['target'] = int(label_included)\n",
    "    return dfs_batches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a766a22b9fcd83d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_shadow_modells_cifar_10_and_get_mi_data(dataset: torch.utils.data.Dataset = cifar10_dataset,\n",
    "                                                  num_shadow_models: int = 16,\n",
    "                                                  num_epochs:int=15):\n",
    "    df_mi_data = []\n",
    "    for _ in tqdm(range(num_shadow_models), leave=False):\n",
    "        #Prep Data\n",
    "        #the original dataset has 50000 train and 10000 test images\n",
    "        #for the shadow models we use 35000 train images, thus we have 25000 images not included in training\n",
    "        included_set, excluded_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "        included_dl = DataLoader(included_set, batch_size=128, num_workers=8, shuffle=True)\n",
    "        excluded_set = DataLoader(excluded_set, batch_size=128, num_workers=8, shuffle=False)\n",
    "\n",
    "        #Model Training\n",
    "        shadow_model = cifar_models.CifarCNNModel(use_log_softmax=False)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(shadow_model.parameters(), lr=0.01)\n",
    "        train_model_no_logs(model=shadow_model, criterion=criterion, optimizer=optimizer, train_dl=included_dl,num_epochs=num_epochs)\n",
    "        \n",
    "        \n",
    "        #Collect MI_Data\n",
    "        indices = random.sample(range(50000),10000)\n",
    "        included_set_reduced = torch.utils.data.Subset(cifar10_dataset_train,indices=indices)\n",
    "        included_dl_reduced = DataLoader(included_set_reduced , batch_size=128, num_workers=8, shuffle=False)\n",
    "        df_mi_data.append(get_mi_data(shadow_model, datal=included_dl_reduced, label_included=True, apply_softmax=True))\n",
    "        df_mi_data.append(get_mi_data(shadow_model, datal=excluded_set, label_included=False, apply_softmax=True))\n",
    "\n",
    "    return pd.concat(df_mi_data)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136986b21f356bef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = train_shadow_modells_cifar_10_and_get_mi_data(num_shadow_models=16)\n",
    "#df.to_csv(f\"{path_configs.MI_DATA_FOLDER}/cifar_shadow_data16.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8509dce2855596f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR-10 Meta Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8954238cd06284"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mi_ds = mi_dataset.MembershipInferenceDataset(df)\n",
    "mi_dataloader = DataLoader(mi_ds,\n",
    "                           batch_size=32,\n",
    "                           num_workers=4,\n",
    "                           shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6d29bb9095b09f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mi_model = membership_inference_meta_classifier.MIMetaClassifierSmall(input_size=10, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mi_model.parameters(), lr=1e-4)\n",
    "\n",
    "train_model_no_logs(mi_model,\n",
    "                    train_dl=mi_dataloader,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=criterion,\n",
    "                    num_epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eb9068279712652"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR-10 Membership Inference Attack"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad97690ae6a19ccd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_mi_data_from_attacked_model(\n",
    "        model: nn.Module,\n",
    "        dl_included: torch.utils.data.DataLoader,\n",
    "        dl_excluded: torch.utils.data.DataLoader,\n",
    "        reverse_log_softmax: bool = True):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    df_mi_data = []\n",
    "    for datal, target in zip([dl_included, dl_excluded], [True, False]):\n",
    "        for model_inputs, _ in datal:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            model_preds = model(model_inputs)\n",
    "            if reverse_log_softmax:\n",
    "                model_preds = torch.exp(model_preds)\n",
    "            df_batch = pd.DataFrame(model_preds.cpu().detach().numpy())\n",
    "            df_batch['target'] = int(target)\n",
    "            df_mi_data.append(df_batch)\n",
    "    df_mi_data = pd.concat(df_mi_data)\n",
    "    return df_mi_data\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_mi_attack(\n",
    "        meta_classifier: nn.Module,\n",
    "        dl: torch.utils.data.DataLoader) -> float:\n",
    "    meta_classifier.eval()\n",
    "    meta_classifier = meta_classifier.to(device)\n",
    "    num_preds = 0\n",
    "    num_correct_preds = 0\n",
    "    for model_inputs, targets in dl:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        preds = meta_classifier(model_inputs)\n",
    "        num_preds += len(preds)\n",
    "        num_correct_preds += (preds.round() == targets).sum()\n",
    "    accuracy_mi = num_correct_preds/num_preds\n",
    "    print(f\"Accuracy MI:{accuracy_mi:.4f}\")\n",
    "    return accuracy_mi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f33660506a31aa7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mi_attack(\n",
    "        attacked_model:nn.Module,\n",
    "        meta_classifier:nn.Module,\n",
    "        included_dl:torch.utils.data.DataLoader,\n",
    "        excluded_dl:torch.utils.data.DataLoader,\n",
    "        reverse_log_softmax:bool=True) -> float:\n",
    "    #get Preds from attacked model\n",
    "    df_preds_from_attacked_model = get_mi_data_from_attacked_model(attacked_model,\n",
    "                                                                   dl_included=included_dl,\n",
    "                                                                   dl_excluded=excluded_dl,\n",
    "                                                                   reverse_log_softmax=reverse_log_softmax)\n",
    "    #turn preds into Dataloader\n",
    "    mi_attack_ds =mi_dataset.MembershipInferenceDataset(df_preds_from_attacked_model)\n",
    "    mi_attack_dl = DataLoader(mi_attack_ds,\n",
    "                           batch_size=64,\n",
    "                           num_workers=4,\n",
    "                           shuffle=True)\n",
    "    #use meta classifier to eval the effektveness of mi attack\n",
    "    return eval_mi_attack(meta_classifier=meta_classifier,dl=mi_attack_dl)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89abf69c8589335b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attacked_model = cifar_models.CifarCNNModel()\n",
    "attacked_model.load_state_dict(torch.load(f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cifar_10_base.pl\"))\n",
    "\n",
    "acc = mi_attack(attacked_model=attacked_model,\n",
    "          meta_classifier=mi_model,\n",
    "          included_dl=DataLoader(cifar10_dataset_train_reduced,batch_size=64,num_workers=4,shuffle=False),\n",
    "          excluded_dl=DataLoader(cifar10_dataset_test,batch_size=64,num_workers=4,shuffle=False))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f409aa8e247fa313"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epsilon in [1,5,10,20,30,50]:\n",
    "    attacked_model = cifar_models.CifarCNNModel()\n",
    "    attacked_model = ModuleValidator.fix(attacked_model)\n",
    "    attacked_model.load_state_dict(torch.load(f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cifar_epsilon{epsilon}.pl\"))\n",
    "    \n",
    "    print(f\"Eval Model with Epsilon={epsilon}\")\n",
    "    mi_attack(attacked_model=attacked_model,\n",
    "          meta_classifier=mi_model,\n",
    "          included_dl=DataLoader(cifar10_dataset_train_reduced,batch_size=64,num_workers=4,shuffle=False),\n",
    "          excluded_dl=DataLoader(cifar10_dataset_test,batch_size=64,num_workers=4,shuffle=False))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c5ed3b389537b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet18 Shadow Modells"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bf69ffd2e260dee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset_celeba = faces_dataset.FacesDataset(label_cols='all', \n",
    "                                               mode=\"train\",\n",
    "                                               transform=torchvision.transforms.Compose(\n",
    "                                                        [torchvision.transforms.ToTensor()]\n",
    "                                                    ))\n",
    "val_dataset_celeba = faces_dataset.FacesDataset(label_cols='all', \n",
    "                                             mode=\"val\", \n",
    "                                             transform=torchvision.transforms.Compose(\n",
    "                                                        [torchvision.transforms.ToTensor()]\n",
    "                                                    ))\n",
    "test_dataset_celeba = faces_dataset.FacesDataset(label_cols='all', \n",
    "                                              mode=\"test\", \n",
    "                                              transform=torchvision.transforms.Compose(\n",
    "                                                        [torchvision.transforms.ToTensor()]\n",
    "                                                    ))\n",
    "\n",
    "#Combien Datasets for training of shadow modells\n",
    "dataset_celeba_combines = torch.utils.data.ConcatDataset([train_dataset_celeba,val_dataset_celeba,test_dataset_celeba])\n",
    "\n",
    "#Get Data for mi attack on model\n",
    "indices = random.sample(range(162770),100000)\n",
    "train_dataset_celeba_reduced = torch.utils.data.Subset(train_dataset_celeba, indices=indices)\n",
    "indluced_dl_celeba = DataLoader(train_dataset_celeba_reduced,batch_size=64,num_workers=8,shuffle=False)\n",
    "\n",
    "excluded_ds_celeba = torch.utils.data.ConcatDataset([test_dataset_celeba,val_dataset_celeba])\n",
    "excluded_dl_celeba = DataLoader(excluded_ds_celeba,batch_size=64,num_workers=8,shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60e5bf06f5ef1482"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_shadow_modells_resnet18_and_get_mi_data(dataset: torch.utils.data.Dataset,\n",
    "                                                  num_shadow_models: int = 8):\n",
    "    df_mi_data = []\n",
    "    for _ in tqdm(range(num_shadow_models), leave=False):\n",
    "        #Prep Data\n",
    "        #the original dataset has 50000 train and 10000 test images\n",
    "        #for the shadow models we use 35000 train images, thus we have 25000 images not included in training\n",
    "        included_set, excluded_set = torch.utils.data.random_split(dataset, [150000, 52599])\n",
    "        included_dl = DataLoader(included_set, batch_size=64, num_workers=8, shuffle=True)\n",
    "        excluded_set = DataLoader(excluded_set, batch_size=64, num_workers=8, shuffle=False)\n",
    "\n",
    "        #Model Training\n",
    "        shadow_model = face_models.get_FaceModelResNet(output_size=40,pretrained=True)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(shadow_model.parameters(), lr=0.01)\n",
    "        train_model_no_logs(model=shadow_model, \n",
    "                            criterion=criterion, \n",
    "                            optimizer=optimizer, \n",
    "                            train_dl=included_dl,\n",
    "                            num_epochs=3)\n",
    "        \n",
    "        #Collect MI_Data\n",
    "        indices = random.sample(range(150000),52000)\n",
    "        included_set_reduced = torch.utils.data.Subset(cifar10_dataset_train,indices=indices)\n",
    "        included_dl_reduced = DataLoader(included_set_reduced , batch_size=128, num_workers=8, shuffle=False)\n",
    "\n",
    "        #Collect MI_Data\n",
    "        df_mi_data.append(get_mi_data(shadow_model, \n",
    "                                      datal=included_dl_reduced, \n",
    "                                      label_included=True, \n",
    "                                      apply_softmax=False))\n",
    "        df_mi_data.append(get_mi_data(shadow_model, \n",
    "                                      datal=excluded_set, \n",
    "                                      label_included=False, \n",
    "                                      apply_softmax=False))\n",
    "\n",
    "    return pd.concat(df_mi_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9209ac299b820145"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = train_shadow_modells_resnet18_and_get_mi_data(dataset=dataset_celeba_combines, num_shadow_models=8)\n",
    "df.to_csv(f\"{path_configs.MI_DATA_FOLDER}/celeba_resnet18_shadow_data8.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "920617a384c72d5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{path_configs.MI_DATA_FOLDER}/celeba_resnet18_shadow_data8.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bc0cfefaf6693fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df= df.groupby('target').sample(n=740000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65de6e0b2ebc307"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train Meta Classifier\n",
    "mi_ds = mi_dataset.MembershipInferenceDataset(df)\n",
    "mi_dataloader = DataLoader(mi_ds,\n",
    "                           batch_size=16,\n",
    "                           num_workers=4,\n",
    "                           shuffle=True)\n",
    "\n",
    "mi_model = membership_inference_meta_classifier.MIMetaClassifierMedium(input_size=40, output_size=1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mi_model.parameters(), lr=1e-8)\n",
    "train_model_no_logs(mi_model,\n",
    "                    train_dl=mi_dataloader,\n",
    "                    optimizer=optimizer,\n",
    "                    criterion=criterion,\n",
    "                    num_epochs=15)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d80189456026266"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Attack Base Model\n",
    "attacked_model = face_models.get_FaceModelResNet(output_size=40,pretrained=False)\n",
    "attacked_model.load_state_dict(torch.load(f\"{path_configs.MODELS_TRAINED_BASE_PATH}/face_base_model.pl\"))\n",
    "mi_attack(attacked_model=attacked_model,\n",
    "          meta_classifier=mi_model,\n",
    "          included_dl=indluced_dl_celeba,\n",
    "          excluded_dl=excluded_dl_celeba)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d53ab11eb74f7adf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Attack DPSGD Models\n",
    "for epsilon in [1,5,10]:\n",
    "    #Load DPSGD Model\n",
    "    attacked_model=face_models.get_FaceModelResNet(output_size=40,pretrained=False)\n",
    "    attacked_model = ModuleValidator.fix(attacked_model)\n",
    "    attacked_model.load_state_dict(torch.load(f\"{path_configs.MODELS_TRAINED_BASE_PATH}/cnn_pretrained_epsilon{epsilon}_epochs3_clipp1e-05_batch256_ohneAA.pl\"))\n",
    "    #Eval MI\n",
    "    print(f\"Eval Model with Epsilon={epsilon}\")\n",
    "    mi_attack(attacked_model=attacked_model,\n",
    "          meta_classifier=mi_model,\n",
    "          included_dl=indluced_dl_celeba,    \n",
    "          excluded_dl=excluded_dl_celeba)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e01e9cd9dba977"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1b81c8f31d4d0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
